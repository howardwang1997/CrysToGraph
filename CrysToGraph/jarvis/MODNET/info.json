{
  "authors": "Pierre-Paul DeBreuck (@ppdebreuck), Matthew Evans (@ml-evs)",
  "algorithm": "MODNet (v0.1.12)",
  "algorithm_long": "[MODNet](https://github.com/ppdebreuck/modnet/releases), the Materials Optimal Descriptor Network (v0.1.12). A feed-forward neural network, using all compatible matminer features and a relevance-redundancy based feature selection algorithm. Hyperparameter optimisation is performed with a nested grid search for the 9 smaller tasks, and with a genetic algorithm for the 4 larger tasks (`matbench_perovskites`, `matbench_mp_gap`, `matbench_mp_is_metal`, `matbench_mp_eform`. Benchmark results were loaded from https://github.com/ml-evs/modnet-matbench/releases/tag/v0.4.0, archived at [10.5281/zenodo.5109941](https://doi.org/10.5281/zenodo.5109941). This latest benchmark uses an improved GA-based hyperparameter optimization.",
  "bibtex_refs": "@article{De_Breuck_2021, doi = {10.1088/1361-648x/ac1280}, url = {https://doi.org/10.1088/1361-648x/ac1280}, year = 2021, month = {jul}, publisher = {{IOP} Publishing}, volume = {33}, number = {40}, pages = {404002}, author = {Pierre-Paul De Breuck and Matthew L Evans and Gian-Marco Rignanese}, title = {Robust model benchmarking and bias-imbalance in data-driven materials science: a case study on {MODNet}}, journal = {Journal of Physics: Condensed Matter}, abstract = {As the number of novel data-driven approaches to material science continues to grow, it is crucial to perform consistent quality, reliability and applicability assessments of model performance. In this paper, we benchmark the Materials Optimal Descriptor Network (MODNet) method and architecture against the recently released MatBench v0.1, a curated test suite of materials datasets. MODNet is shown to outperform current leaders on 6 of the 13 tasks, while closely matching the current leaders on a further 2 tasks; MODNet performs particularly well when the number of samples is below 10Â 000. Attention is paid to two topics of concern when benchmarking models. First, we encourage the reporting of a more diverse set of metrics as it leads to a more comprehensive and holistic comparison of model performance. Second, an equally important task is the uncertainty assessment of a model towards a target domain. Significant variations in validation errors can be observed, depending on the imbalance and bias in the training set (i.e., similarity between training and application space). By using an ensemble MODNet model, confidence intervals can be built and the uncertainty on individual predictions can be quantified. Imbalance and bias issues are often overlooked, and yet are important for successful real-world applications of machine learning in materials science and condensed matter.}}, @article{DeBreuck2021, doi = {10.1038/s41524-021-00552-2}, url = {https://doi.org/10.1038/s41524-021-00552-2}, year = {2021}, month = jun, publisher = {Springer Science and Business Media {LLC}}, volume = {7}, number = {1}, author = {Pierre-Paul De Breuck and Geoffroy Hautier and Gian-Marco Rignanese}, title = {Materials property prediction for limited datasets enabled by feature selection and joint learning with {MODNet}}, journal = {npj Computational Materials}}",
  "notes": null,
  "requirements": {"python":  ["modnet==0.1.12", "matbench==0.2.0"]}
}
